# -*- coding: utf-8 -*-
"""Week6_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dSsZSQtjM4eeRZq7U-4zWFrt3TfT74Jj
"""

import re
import numpy as np
import pandas as pd
import xml.etree.ElementTree as ET
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

# 讀取 XML
xml_file = "./O-A0038-003.xml"
tree = ET.parse(xml_file)
root = tree.getroot()
ns = {"cwa": "urn:cwa:gov:tw:cwacommon:0.1"}

content = root.find(".//cwa:Content", ns).text
lon_start = float(root.find(".//cwa:BottomLeftLongitude", ns).text)
lat_start = float(root.find(".//cwa:BottomLeftLatitude", ns).text)
lon_end   = float(root.find(".//cwa:TopRightLongitude", ns).text)
lat_end   = float(root.find(".//cwa:TopRightLatitude", ns).text)

lon_step, lat_step = 0.03, 0.03
nx = int(round((lon_end - lon_start) / lon_step)) + 1
ny = int(round((lat_end - lat_start) / lat_step)) + 1
print(f"Grid size = {ny} x {nx}")

clean_str = re.sub(r"\s+", " ", content.strip())
values = re.findall(r"[-+]?\d+\.?\d*E[+-]?\d+", clean_str)
values = [float(v) for v in values]
if len(values) != nx * ny:
    print(f"⚠️ 讀到 {len(values)} 筆，與期望 {nx*ny} 筆不符！")

grid = np.array(values).reshape(ny, nx)

lons = np.linspace(lon_start, lon_end, nx)
lats = np.linspace(lat_start, lat_end, ny)
lon_grid, lat_grid = np.meshgrid(lons, lats)

# 分類資料集
labels = (grid != -999.0).astype(int)
cls_data = pd.DataFrame({
    "lon": lon_grid.ravel(),
    "lat": lat_grid.ravel(),
    "label": labels.ravel()
})

# 回歸資料集
mask = grid != -999.0
reg_data = pd.DataFrame({
    "lon": lon_grid[mask],
    "lat": lat_grid[mask],
    "value": grid[mask]
})

# 四捨五入 (解決 120.57000000000001 問題)
for df in (cls_data, reg_data):
    df["lon"] = df["lon"].round(2)
    df["lat"] = df["lat"].round(2)

# 輸出 CSV
cls_data.to_csv("./classification_dataset.csv", index=False)
reg_data.to_csv("./regression_dataset.csv", index=False)

print("✅ 已輸出 classification_dataset.csv 與 regression_dataset.csv")

# 分類模型 (cls_data)
X_cls = cls_data[["lon", "lat"]].values
y_cls = cls_data["label"].values

scaler = StandardScaler()
X_cls = scaler.fit_transform(X_cls)

X_train, X_val, y_train, y_val = train_test_split(
    X_cls, y_cls, test_size=0.2, random_state=42
)

classes = np.unique(y_train)
n_classes = len(classes)
n_features = X_train.shape[1]

# 平均 μ_k
mu = np.array([X_train[y_train == k].mean(axis=0) for k in classes])

# 共用共變異矩陣 Σ
Sigma = np.zeros((n_features, n_features))
for k in classes:
    Xk = X_train[y_train == k]
    diff = Xk - mu[k]
    Sigma += diff.T @ diff
Sigma /= len(X_train)

# 先驗機率 π_k
pi = np.array([np.mean(y_train == k) for k in classes])

# 共變異矩陣的逆與行列式
Sigma_inv = np.linalg.inv(Sigma)
Sigma_det = np.linalg.det(Sigma)

def predict_gda(X):
    log_probs = []
    for k in classes:
        diff = X - mu[k]
        lp = -0.5 * np.sum(diff @ Sigma_inv * diff, axis=1)
        lp -= 0.5 * np.log(Sigma_det)
        lp += np.log(pi[k])
        log_probs.append(lp)
    log_probs = np.vstack(log_probs).T
    return np.argmax(log_probs, axis=1)

# 驗證
y_pred = predict_gda(X_val)
acc = np.mean(y_pred == y_val)
print(f"✅ Validation Accuracy: {acc:.4f}")

xx, yy = np.meshgrid(
    np.linspace(X_cls[:, 0].min(), X_cls[:, 0].max(), 200),
    np.linspace(X_cls[:, 1].min(), X_cls[:, 1].max(), 200)
)
grid_points = np.c_[xx.ravel(), yy.ravel()]
Z = predict_gda(grid_points).reshape(xx.shape)

plt.figure(figsize=(6, 5))
plt.contourf(xx, yy, Z, alpha=0.4, cmap="coolwarm")
plt.scatter(X_cls[:, 0], X_cls[:, 1], c=y_cls, edgecolor="k", cmap="coolwarm", s=20)
plt.xlabel("Longitude (standardized)")
plt.ylabel("Latitude (standardized)")
plt.title("Gaussian Discriminant Analysis Decision Boundary")
plt.show()