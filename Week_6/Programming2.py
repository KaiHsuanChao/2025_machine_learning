# -*- coding: utf-8 -*-
"""Week6_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x5CP2ewFsiL1jS_52ZiQBIm1Q-mejpLe
"""

import re
import numpy as np
import pandas as pd
import xml.etree.ElementTree as ET
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

# 讀取 XML
xml_file = "./O-A0038-003.xml"
tree = ET.parse(xml_file)
root = tree.getroot()
ns = {"cwa": "urn:cwa:gov:tw:cwacommon:0.1"}

content = root.find(".//cwa:Content", ns).text
lon_start = float(root.find(".//cwa:BottomLeftLongitude", ns).text)
lat_start = float(root.find(".//cwa:BottomLeftLatitude", ns).text)
lon_end   = float(root.find(".//cwa:TopRightLongitude", ns).text)
lat_end   = float(root.find(".//cwa:TopRightLatitude", ns).text)

lon_step, lat_step = 0.03, 0.03
nx = int(round((lon_end - lon_start) / lon_step)) + 1
ny = int(round((lat_end - lat_start) / lat_step)) + 1
print(f"Grid size = {ny} x {nx}")

clean_str = re.sub(r"\s+", " ", content.strip())
values = re.findall(r"[-+]?\d+\.?\d*E[+-]?\d+", clean_str)
values = [float(v) for v in values]
if len(values) != nx * ny:
    print(f"⚠️ 讀到 {len(values)} 筆，與期望 {nx*ny} 筆不符！")

grid = np.array(values).reshape(ny, nx)

lons = np.linspace(lon_start, lon_end, nx)
lats = np.linspace(lat_start, lat_end, ny)
lon_grid, lat_grid = np.meshgrid(lons, lats)

# 資料集建立
labels = (grid != -999.0).astype(int)  # 1 = 有值, 0 = 缺值
cls_data = pd.DataFrame({
    "lon": lon_grid.ravel(),
    "lat": lat_grid.ravel(),
    "label": labels.ravel(),
    "value": grid.ravel()
})

# 四捨五入避免浮點誤差
cls_data["lon"] = cls_data["lon"].round(2)
cls_data["lat"] = cls_data["lat"].round(2)

# 訓練 / 驗證集拆分
X = cls_data[["lon", "lat"]].values
y_cls = cls_data["label"].values
y_reg = cls_data["value"].values

scaler = StandardScaler()
X = scaler.fit_transform(X)

X = torch.tensor(X, dtype=torch.float32)
y_cls = torch.tensor(y_cls, dtype=torch.long)
y_reg = torch.tensor(y_reg, dtype=torch.float32).view(-1, 1)

X_train, X_val, y_cls_train, y_cls_val, y_reg_train, y_reg_val = train_test_split(
    X, y_cls, y_reg, test_size=0.2, random_state=42
)

# 定義 Hybrid Model
class HybridModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.shared = nn.Sequential(
            nn.Linear(2, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU(),
        )
        self.cls_head = nn.Linear(32, 2)
        self.reg_head = nn.Linear(32, 1)

    def forward(self, x):
        feat = self.shared(x)
        cls_out = self.cls_head(feat)
        reg_out = self.reg_head(feat)
        return cls_out, reg_out

model = HybridModel()
optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)
criterion_cls = nn.CrossEntropyLoss()
criterion_reg = nn.MSELoss()

# 訓練迴圈
train_cls_losses, val_cls_losses, val_accs, train_reg_losses, val_reg_losses = [], [], [], [], []
epochs = 200

for epoch in range(epochs):
    model.train()
    optimizer.zero_grad()

    cls_pred, reg_pred = model(X_train)
    loss_cls = criterion_cls(cls_pred, y_cls_train)

    mask = y_cls_train == 1
    if mask.any():
        loss_reg = criterion_reg(reg_pred[mask], y_reg_train[mask])
    else:
        loss_reg = torch.tensor(0.0)

    loss = loss_cls + 0.1 * loss_reg
    loss.backward()
    optimizer.step()

    # ===== Validation =====
    model.eval()
    with torch.no_grad():
        val_cls_pred, val_reg_pred = model(X_val)
        val_loss_cls = criterion_cls(val_cls_pred, y_cls_val)

        mask_val = y_cls_val == 1
        if mask_val.any():
            val_loss_reg = criterion_reg(val_reg_pred[mask_val], y_reg_val[mask_val])
        else:
            val_loss_reg = torch.tensor(0.0)

        acc = (val_cls_pred.argmax(dim=1) == y_cls_val).float().mean().item()

    train_cls_losses.append(loss_cls.item())
    val_cls_losses.append(val_loss_cls.item())
    val_accs.append(acc)
    train_reg_losses.append(loss_reg.item())
    val_reg_losses.append(val_loss_reg.item())

    if epoch % 10 == 0:
        print(f"[Epoch {epoch}] "
              f"Cls Loss: {loss_cls.item():.4f}, Val Cls: {val_loss_cls.item():.4f}, "
              f"Reg Loss: {loss_reg.item():.4f}, Val Reg: {val_loss_reg.item():.4f}, "
              f"Val Acc: {acc:.4f}")

# 訓練曲線繪圖
plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(train_cls_losses, label="Train Cls Loss")
plt.plot(val_cls_losses, label="Val Cls Loss")
plt.xlabel("Epoch"); plt.ylabel("Loss"); plt.title("Classification Loss")
plt.legend()

plt.subplot(1,2,2)
plt.plot(val_accs, label="Val Accuracy")
plt.xlabel("Epoch"); plt.ylabel("Accuracy")
plt.title("Classification Accuracy")
plt.legend()
plt.tight_layout()
plt.show()

plt.figure(figsize=(6,4))
plt.plot(train_reg_losses, label="Train Reg Loss")
plt.plot(val_reg_losses, label="Val Reg Loss")
plt.xlabel("Epoch"); plt.ylabel("MSE Loss")
plt.legend()
plt.title("Regression Loss")
plt.show()

# 輸出組合 h(x)
model.eval()
with torch.no_grad():
    cls_out, reg_out = model(X)
    cls_label = cls_out.argmax(dim=1)
    final_pred = torch.where(cls_label == 1, reg_out.squeeze(), torch.tensor(-999.0))

